#!/usr/bin/env python3
"""
Final Meta Ensemble 90% Push - Implementasi meta-learner ensemble
Berdasarkan analisis gap: simple mean voting (57.38%) vs meta-learner (87.19%)
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
import torch
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score, f1_score
from sklearn.utils.class_weight import compute_class_weight
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

class HateSpeechDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

class MetaEnsembleTrainer:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”¥ Using device: {self.device}")
        
        # Model configurations - menggunakan model yang tersedia
        self.model_configs = [
            {
                'name': 'indoroberta',
                'model_name': 'flax-community/indonesian-roberta-base',
                'learning_rate': 2e-5,
                'warmup_steps': 400
            },
            {
                'name': 'bert_multilingual',
                'model_name': 'bert-base-multilingual-cased',
                'learning_rate': 2e-5,
                'warmup_steps': 500
            },
            {
                'name': 'xlm_roberta',
                'model_name': 'xlm-roberta-base',
                'learning_rate': 1e-5,
                'warmup_steps': 300
            }
        ]
        
        # Label mapping
        self.label_map = {
            'Bukan Ujaran Kebencian': 0,
            'Ujaran Kebencian - Ringan': 1, 
            'Ujaran Kebencian - Sedang': 2,
            'Ujaran Kebencian - Berat': 3
        }
        
        # Results storage
        self.results = {
            'experiment_name': 'final_meta_ensemble_90_percent',
            'timestamp': datetime.now().isoformat(),
            'target_achieved': False,
            'models': {},
            'meta_ensemble_results': {},
            'best_f1_macro': 0.0
        }

    def load_and_prepare_data(self):
        """Load dataset yang sama dengan successful experiment"""
        print("ğŸ“Š Loading balanced dataset...")
        
        # Load dataset yang terbukti bagus
        df = pd.read_csv('data/standardized/balanced_dataset.csv')
        print(f"Dataset shape: {df.shape}")
        print(f"Label distribution:\n{df['final_label'].value_counts()}")
        
        # Clean data
        df = df.dropna(subset=['text', 'final_label'])
        print(f"Dataset shape after cleaning: {df.shape}")
        
        # Advanced preprocessing
        df = self.advanced_preprocessing(df)
        
        # Prepare features and labels
        X = df['text'].values
        y = df['final_label'].map(self.label_map).values
        
        # Split data - sama seperti successful experiment
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        print(f"Train samples: {len(X_train)}")
        print(f"Test samples: {len(X_test)}")
        print(f"Train label distribution: {np.bincount(y_train)}")
        print(f"Test label distribution: {np.bincount(y_test)}")
        
        return X_train, X_test, y_train, y_test

    def advanced_preprocessing(self, df):
        """Advanced text preprocessing"""
        print("ğŸ”§ Applying advanced preprocessing...")
        
        # Text cleaning
        df['text'] = df['text'].str.strip()
        df['text'] = df['text'].str.replace(r'\s+', ' ', regex=True)
        df['text'] = df['text'].str.replace(r'[^\w\s]', ' ', regex=True)
        
        # Remove very short texts
        df = df[df['text'].str.len() >= 10]
        
        print(f"Dataset shape after preprocessing: {df.shape}")
        return df

    def create_dataset(self, texts, labels, tokenizer, max_length=128):
        """Create dataset for training"""
        encodings = tokenizer(
            list(texts),
            truncation=True,
            padding=True,
            max_length=max_length,
            return_tensors='pt'
        )
        return HateSpeechDataset(encodings, labels)

    def train_single_model(self, config, X_train, X_test, y_train, y_test):
        """Train single model dengan konfigurasi optimal"""
        print(f"\nğŸ¤– Training {config['name']}...")
        
        # Load tokenizer and model
        tokenizer = AutoTokenizer.from_pretrained(config['model_name'])
        model = AutoModelForSequenceClassification.from_pretrained(
            config['model_name'],
            num_labels=4
        ).to(self.device)
        
        # Create datasets
        train_dataset = self.create_dataset(X_train, y_train, tokenizer)
        test_dataset = self.create_dataset(X_test, y_test, tokenizer)
        
        # Compute class weights
        class_weights = compute_class_weight(
            'balanced',
            classes=np.unique(y_train),
            y=y_train
        )
        class_weights = torch.FloatTensor(class_weights).to(self.device)
        
        # Training arguments - optimized untuk performance
        training_args = TrainingArguments(
            output_dir=f'tmp_meta_{config["name"]}',
            num_train_epochs=5,  # Optimal epochs
            per_device_train_batch_size=16,
            per_device_eval_batch_size=32,
            warmup_steps=config['warmup_steps'],
            weight_decay=0.01,
            logging_dir=f'logs_meta_{config["name"]}',
            logging_steps=100,
            eval_strategy='steps',
            eval_steps=200,
            save_strategy='steps',
            save_steps=400,
            load_best_model_at_end=True,
            metric_for_best_model='f1',
            greater_is_better=True,
            learning_rate=config['learning_rate'],
            lr_scheduler_type='linear',  # Linear scheduler seperti successful experiment
            fp16=True,
            dataloader_num_workers=0,
            gradient_accumulation_steps=2,
            max_grad_norm=1.0,
            seed=42
        )
        
        # Custom trainer dengan focal loss
        class FocalLossTrainer(Trainer):
            def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
                labels = inputs.get("labels")
                outputs = model(**inputs)
                logits = outputs.get('logits')
                
                # Focal loss implementation
                ce_loss = torch.nn.functional.cross_entropy(logits, labels, reduction='none')
                pt = torch.exp(-ce_loss)
                focal_loss = (1 - pt) ** 2 * ce_loss
                loss = focal_loss.mean()
                
                return (loss, outputs) if return_outputs else loss
        
        # Custom metrics
        def compute_metrics(eval_pred):
            predictions, labels = eval_pred
            predictions = np.argmax(predictions, axis=1)
            f1_macro = f1_score(labels, predictions, average='macro')
            f1_weighted = f1_score(labels, predictions, average='weighted')
            accuracy = accuracy_score(labels, predictions)
            return {
                'f1': f1_macro,
                'f1_weighted': f1_weighted,
                'accuracy': accuracy
            }
        
        # Initialize trainer
        trainer = FocalLossTrainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
        )
        
        # Train model
        print(f"ğŸš€ Starting training for {config['name']}...")
        trainer.train()
        
        # Evaluate model
        print(f"ğŸ“Š Evaluating {config['name']}...")
        eval_results = trainer.evaluate()
        
        # Get predictions for meta-learner
        predictions = trainer.predict(test_dataset)
        pred_probs = torch.softmax(torch.tensor(predictions.predictions), dim=1).numpy()
        pred_labels = np.argmax(pred_probs, axis=1)
        
        # Calculate detailed metrics
        accuracy = accuracy_score(y_test, pred_labels)
        f1_macro = f1_score(y_test, pred_labels, average='macro')
        f1_weighted = f1_score(y_test, pred_labels, average='weighted')
        
        target_names = ['Bukan Ujaran Kebencian', 'Ujaran Kebencian - Ringan', 'Ujaran Kebencian - Sedang', 'Ujaran Kebencian - Berat']
        class_report = classification_report(y_test, pred_labels, target_names=target_names, output_dict=True)
        
        model_results = {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'classification_report': class_report,
            'eval_results': eval_results
        }
        
        print(f"âœ… {config['name']} Results:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   F1-Macro: {f1_macro:.4f}")
        print(f"   F1-Weighted: {f1_weighted:.4f}")
        
        return model_results, pred_probs

    def train_meta_learner(self, all_predictions, y_test):
        """Train meta-learner seperti successful experiment"""
        print("\nğŸ§  Training meta-learner (Random Forest)...")
        
        # Prepare meta-features
        meta_features = np.hstack(all_predictions)  # Concatenate all model predictions
        print(f"Meta-features shape: {meta_features.shape}")
        
        # Split meta-features for validation
        X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(
            meta_features, y_test, test_size=0.3, random_state=42, stratify=y_test
        )
        
        # Train Random Forest meta-learner
        meta_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        meta_model.fit(X_meta_train, y_meta_train)
        
        # Validate meta-learner
        val_predictions = meta_model.predict(X_meta_val)
        val_f1 = f1_score(y_meta_val, val_predictions, average='macro')
        print(f"Meta-learner validation F1-Macro: {val_f1:.4f}")
        
        # Final prediction on full test set
        final_predictions = meta_model.predict(meta_features)
        
        # Calculate final metrics
        accuracy = accuracy_score(y_test, final_predictions)
        f1_macro = f1_score(y_test, final_predictions, average='macro')
        f1_weighted = f1_score(y_test, final_predictions, average='weighted')
        
        target_names = ['Bukan Ujaran Kebencian', 'Ujaran Kebencian - Ringan', 'Ujaran Kebencian - Sedang', 'Ujaran Kebencian - Berat']
        class_report = classification_report(y_test, final_predictions, target_names=target_names, output_dict=True)
        
        meta_results = {
            'meta_model': 'random_forest',
            'validation_f1_macro': val_f1,
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'classification_report': class_report,
            'predictions': final_predictions.tolist()
        }
        
        print(f"ğŸ¯ Meta-Ensemble Results:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   F1-Macro: {f1_macro:.4f}")
        print(f"   F1-Weighted: {f1_weighted:.4f}")
        
        return meta_results

    def run_experiment(self):
        """Run complete meta-ensemble experiment"""
        print("ğŸš€ Starting Final Meta-Ensemble 90% Push Experiment")
        print("="*70)
        
        # Load data
        X_train, X_test, y_train, y_test = self.load_and_prepare_data()
        
        # Train multiple models
        all_predictions = []
        
        for config in self.model_configs:
            try:
                model_results, predictions = self.train_single_model(
                    config, X_train, X_test, y_train, y_test
                )
                self.results['models'][config['name']] = model_results
                all_predictions.append(predictions)
                
                # Update best score
                if model_results['f1_macro'] > self.results['best_f1_macro']:
                    self.results['best_f1_macro'] = model_results['f1_macro']
                
                # Check if single model achieves 90%
                if model_results['f1_macro'] >= 0.90:
                    print(f"ğŸ‰ TARGET ACHIEVED! {config['name']} reached {model_results['f1_macro']:.4f} F1-Macro")
                    self.results['target_achieved'] = True
                    
            except Exception as e:
                print(f"âŒ Error training {config['name']}: {str(e)}")
                continue
        
        # Train meta-learner if we have multiple models
        if len(all_predictions) >= 2:
            meta_results = self.train_meta_learner(all_predictions, y_test)
            self.results['meta_ensemble_results'] = meta_results
            
            # Update best score with meta-ensemble
            if meta_results['f1_macro'] > self.results['best_f1_macro']:
                self.results['best_f1_macro'] = meta_results['f1_macro']
            
            # Check if meta-ensemble achieves 90%
            if meta_results['f1_macro'] >= 0.90:
                print(f"ğŸ‰ TARGET ACHIEVED! Meta-Ensemble reached {meta_results['f1_macro']:.4f} F1-Macro")
                self.results['target_achieved'] = True
        else:
            print("âš ï¸ Not enough models for meta-ensemble")
        
        # Save results
        results_file = 'results/final_meta_ensemble_90_percent_results.json'
        os.makedirs('results', exist_ok=True)
        
        with open(results_file, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        
        # Final summary
        print("\n" + "="*70)
        print("ğŸ FINAL RESULTS SUMMARY")
        print("="*70)
        print(f"Best F1-Macro achieved: {self.results['best_f1_macro']:.4f}")
        print(f"Target 90% achieved: {self.results['target_achieved']}")
        
        if 'meta_ensemble_results' in self.results and 'f1_macro' in self.results['meta_ensemble_results']:
            meta_f1 = self.results['meta_ensemble_results']['f1_macro']
            print(f"Meta-Ensemble F1-Macro: {meta_f1:.4f}")
            
            if meta_f1 >= 0.90:
                print("ğŸ‰ SUCCESS: Meta-Ensemble achieved 90% F1-Macro target!")
            else:
                gap = 0.90 - meta_f1
                print(f"ğŸ“Š Gap to 90%: {gap:.4f} ({gap*100:.2f}%)")
        else:
            print("ğŸ“Š No meta-ensemble available (need multiple models)")
            gap = 0.90 - self.results['best_f1_macro']
            print(f"ğŸ“Š Gap to 90% (best single model): {gap:.4f} ({gap*100:.2f}%)")
        
        print(f"Results saved to: {results_file}")
        return self.results

if __name__ == "__main__":
    trainer = MetaEnsembleTrainer()
    results = trainer.run_experiment()