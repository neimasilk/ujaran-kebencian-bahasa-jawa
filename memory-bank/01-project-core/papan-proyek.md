# Papan Proyek - Sistem Deteksi Ujaran Kebencian Bahasa Jawa

### STATUS [Update: 2025-01-03 - Advanced Model Optimization Complete]
- ‚úÖ Proyek telah disiapkan sesuai dengan Vibe Coding Guide v1.4
- ‚úÖ Spesifikasi produk telah diperbaiki dan disesuaikan dengan template PRD
- ‚úÖ Tim manifest telah disiapkan dengan peran yang jelas
- ‚úÖ Environment setup dan modular code structure telah diimplementasi
- ‚úÖ Dataset inspection dan basic testing infrastructure telah selesai
- ‚úÖ **PELABELAN DATASET SELESAI** - 41,346 samples berlabel tersedia di `hasil-labeling.csv`
- ‚úÖ **EKSPERIMEN 1 SELESAI** - IndoBERT baseline dengan 73.8% accuracy (class imbalance terdeteksi)
- ‚úÖ **EKSPERIMEN 2 SELESAI** - Model diperbaiki dengan class weighting + focal loss, F1-Score Macro meningkat dari 40% ‚Üí 80.36%
- ‚úÖ **CLASS IMBALANCE SOLVED** - Stratified sampling, class weighting, dan focal loss berhasil diterapkan
- ‚úÖ **THRESHOLD OPTIMIZATION COMPLETE** - Per-class threshold tuning menghasilkan performa optimal
- ‚úÖ **DOKUMENTASI LENGKAP** - Comprehensive experiment documentation dan evaluation reports tersedia
- ‚úÖ **GPU ACCELERATION SUPPORT** - Mixed precision, automatic device detection, batch size optimization
- ‚úÖ **ARCHITECTURAL REVIEW COMPLETE** - Comprehensive architecture analysis dan roadmap tersedia
- üéØ **SIAP UNTUK ADVANCED EXPERIMENTS** - Model baseline 80.36% F1-Score, target >85% untuk eksperimen lanjutan

### REFERENSI ARSIP
- Baby-step sebelumnya: Implementasi Testing dan Dokumentasi API (selesai)
- Arsip lengkap tersedia di: `baby-steps-archive/`

### BABY-STEP SAAT INI

**"Advanced Model Experiments - Target >85% F1-Score"** üöÄ PRIORITAS TINGGI
- **Tujuan:** Meningkatkan performa model dari baseline 80.36% F1-Score Macro ke target >85% melalui eksperimen lanjutan.
- **Baseline Saat Ini:** F1-Score Macro 80.36%, Accuracy 80.37%
- **Tugas:**
     - [x] ‚úÖ **T1: IndoBERT Large Experiment** | **File:** `experiments/experiment_1_indobert_large.py` | **Status:** IMPLEMENTED & READY | **Target:** +3% improvement (83.36% F1-Score) | **Features:** WeightedFocalLoss, Custom Trainer, Comprehensive Evaluation | **Assignee:** AI Assistant
     - [ ] **T2: XLM-RoBERTa Cross-lingual Experiment** | **File:** `experiments/experiment_2_xlm_roberta.py` | **Tes:** XLM-RoBERTa model dilatih untuk leverage multilingual representation | **Assignee:** AI Assistant
     - [ ] **T3: Advanced Training Techniques** | **File:** `experiments/advanced_training_techniques.py` | **Tes:** Multi-stage fine-tuning dan advanced loss functions diimplementasi | **Assignee:** AI Assistant
     - [ ] **T4: Ensemble Methods Development** | **File:** `experiments/ensemble_methods.py` | **Tes:** Heterogeneous ensemble dari multiple models untuk performa optimal | **Assignee:** AI Assistant

### BABY-STEP SELANJUTNYA

**"API Development & Model Serving"** ‚è≥ FASE BERIKUTNYA
- **Tujuan:** Membangun API FastAPI untuk serving model terbaik dan membuat endpoint untuk prediksi ujaran kebencian.
- **Prasyarat:** ‚úÖ Model optimization experiments selesai, model terbaik dipilih

**"Production Deployment & Monitoring"** ‚è≥ FASE LANJUTAN
- **Tujuan:** Deploy model ke production dengan monitoring dan observability yang komprehensif.

**"Frontend Development & User Interface"** ‚è≥ FASE AKHIR
- **Tujuan:** Membangun antarmuka pengguna untuk demo dan testing model secara interaktif.

### REFERENSI ARSIP
- **Arsip 1:** Production Deployment & Real Data Labeling (selesai)
- **Arsip 2:** Implementasi Testing dan Dokumentasi API (selesai)
- Arsip lengkap tersedia di: `baby-steps-archive/`

## ‚úÖ Selesai Dikerjakan

### T5: Infrastructure Hardening & Data Labeling Preparation - SELESAI ‚úÖ
- T5.1: Architecture Review - SELESAI ‚úÖ
- T5.2: Dependencies Management - SELESAI ‚úÖ
- T5.3: Configuration Management - SELESAI ‚úÖ
- T5.4: Logging Infrastructure - SELESAI ‚úÖ
- T5.5: Documentation Consolidation - SELESAI ‚úÖ
- T4.3: Project Structure Reorganization - SELESAI ‚úÖ
- T5.6: Documentation Enhancement & Team Onboarding - SELESAI ‚úÖ
- T5.7: Parallel DeepSeek API Labeling Implementation - SELESAI ‚úÖ
- T5.8: Comprehensive Testing & Tutorial Documentation - SELESAI ‚úÖ

### SARAN & RISIKO (Review Arsitek)

**üìä ANALISIS DATASET BERLABEL:**
- **Volume:** 41,346 samples (excellent size untuk training)
- **Format:** CSV dengan kolom: text, original_label, final_label, confidence_score, response_time, labeling_method, error
- **Label Distribution:** Perlu analisis distribusi 4-class labels untuk mendeteksi class imbalance
- **Quality:** Confidence scores tersedia untuk quality filtering (threshold >= 0.7 recommended)
- **Status:** ‚úÖ Dataset ready for training dengan preprocessing pipeline terimplementasi

**üéØ Saran Teknis untuk Training:**
- ‚úÖ **SELESAI:** Label mapping dari string ke numerik (0: Bukan Ujaran Kebencian, 1: Ringan, 2: Sedang, 3: Berat)
- ‚úÖ **SELESAI:** Data preprocessing khusus Bahasa Jawa (normalisasi teks, handling dialek)
- ‚úÖ **SELESAI:** Stratified train-test split untuk mengatasi potential class imbalance
- ‚úÖ **SELESAI:** Early stopping dan model checkpointing untuk training stability
- **NEXT:** API Development - FastAPI endpoints untuk model serving
- **NEXT:** Model evaluation framework dengan comprehensive metrics

**‚ö†Ô∏è Risiko Teknis (Updated 2025-01-03):**
- **TINGGI:** Advanced Model Experiments - Eksperimen dengan model yang lebih besar memerlukan computational resources yang signifikan
- **TINGGI:** Ensemble Methods - Kompleksitas implementasi dan potential overfitting
- **SEDANG:** API Layer Development - Belum ada implementasi FastAPI endpoints untuk model serving
- **SEDANG:** Production Deployment - Perlu infrastructure untuk model versioning dan A/B testing
- **RENDAH:** Inference Speed - Model yang lebih besar atau ensemble dapat mempengaruhi latency
- **MITIGATED:** Class imbalance - Sudah diselesaikan dengan stratified sampling, class weighting, dan focal loss
- **MITIGATED:** Evaluation Bias - Balanced evaluation methodology sudah diimplementasi
- **MITIGATED:** Threshold Optimization - Per-class threshold tuning sudah dilakukan

**üîß Mitigasi Strategies:**
- Implementasi class weights dalam loss function untuk mengatasi imbalance
- Gunakan confidence score filtering untuk meningkatkan kualitas training data
- Setup gradient accumulation jika memory terbatas
- Implementasi k-fold cross validation untuk robust evaluation

**üéØ Saran Teknis Lanjutan:**
- **Prioritas 1:** Fokus pada kualitas data labeling - ini akan menentukan 80% dari performa model
- **Prioritas 2:** Setup environment yang konsisten untuk semua developer menggunakan virtual environment
- **Prioritas 3:** Implementasi logging yang komprehensif sejak awal untuk debugging dan monitoring
- **Best Practice:** Gunakan configuration management untuk semua parameter model dan API

**‚ö†Ô∏è Risiko Teknis:**
- **TINGGI:** Kualitas dataset - inconsistent labeling dapat merusak model performance
- **SEDANG:** IndoBERT compatibility dengan Bahasa Jawa - perlu extensive testing
- **SEDANG:** Dependencies conflicts - beberapa library ML memiliki version requirements yang strict
- **RENDAH:** API performance - model inference time perlu dioptimasi untuk production

**üîß Mitigasi:**
- Buat clear labeling guidelines dan quality control process
- Prepare fallback model strategy jika IndoBERT tidak optimal
- Use pinned versions di requirements.txt dan virtual environment
- Implement model caching dan async processing untuk API