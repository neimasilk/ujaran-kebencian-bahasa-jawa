# Panduan Perbaikan Model Hate Speech Detection Bahasa Jawa

## üö® Masalah yang Ditemukan

Setelah evaluasi mendalam, ditemukan beberapa masalah kritis pada model:

### 1. **Bias Evaluasi Akibat Data Ordering**
- **Masalah**: Dataset `hasil-labeling.csv` tersusun berurutan berdasarkan label
- **Dampak**: Evaluasi awal menunjukkan akurasi 95.5% yang **menyesatkan**
- **Realitas**: Model memprediksi SEMUA sampel sebagai "Bukan Ujaran Kebencian"

### 2. **Severe Class Imbalance**
- **Distribusi Data**:
  - Bukan Ujaran Kebencian: ~85% dari dataset
  - Ujaran Kebencian (semua kategori): ~15% dari dataset
- **Dampak**: Model bias terhadap kelas mayoritas

### 3. **Performa Aktual Model**
- **Akurasi Sebenarnya**: 73.8% (bukan 95.5%)
- **F1-Score Macro**: Sangat rendah untuk deteksi hate speech
- **Precision/Recall**: Tidak seimbang antar kelas

## üîß Solusi yang Diimplementasikan

### 1. **Analisis Dataset dan Balanced Evaluation**

#### Script: `analyze_dataset_distribution.py`
**Fungsi**:
- Menganalisis distribusi label dalam dataset
- Membuat balanced evaluation set (200 sampel per kelas)
- Mengatasi bias ordering dengan stratified sampling

**Hasil**:
- Dataset balanced untuk evaluasi yang akurat
- Insight tentang distribusi data yang sebenarnya

#### Script: `balanced_evaluation.py`
**Fungsi**:
- Evaluasi model menggunakan balanced dataset
- Metrics yang komprehensif per kelas
- Confusion matrix untuk analisis detail

**Hasil**:
- Akurasi aktual: 73.8%
- Detailed per-class performance metrics
- Identifikasi bias model terhadap "Bukan Ujaran Kebencian"

### 2. **Improved Training Strategy**

#### Script: `improved_training_strategy.py`
**Fitur Utama**:
- **Stratified Sampling**: Memastikan distribusi seimbang di train/val split
- **Class Weighting**: Memberikan bobot lebih tinggi pada kelas minoritas
- **Focal Loss**: Mengatasi class imbalance dengan loss function yang adaptif
- **Weighted Random Sampler**: Sampling yang seimbang selama training

**Implementasi**:
```python
# Class weights untuk mengatasi imbalance
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=unique_labels,
    y=labels
)

# Focal Loss untuk fokus pada hard examples
class FocalLossTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        # Implementasi focal loss dengan class weighting
        focal_loss = alpha * (1 - pt) ** gamma * ce_loss
```

### 3. **Threshold Tuning**

#### Script: `threshold_tuning.py`
**Fungsi**:
- Mencari threshold optimal untuk setiap kelas
- Optimasi berdasarkan F1-score per kelas
- Evaluasi performa dengan threshold yang disesuaikan

**Manfaat**:
- Meningkatkan deteksi hate speech tanpa mengorbankan akurasi keseluruhan
- Threshold yang dapat disesuaikan untuk production needs
- Balance antara precision dan recall

### 4. **Production-Ready Deployment**

#### Script: `production_deployment.py`
**Fitur**:
- **ProductionHateSpeechDetector**: Class untuk inference yang optimized
- **Threshold Integration**: Menggunakan threshold yang sudah di-tune
- **Monitoring**: Tracking performa dan processing time
- **API Wrapper**: Interface untuk deployment
- **Health Check**: Monitoring system health

**Capabilities**:
- Single dan batch prediction
- Real-time monitoring
- Configuration export/import
- Error handling yang robust

## üìä Perbandingan Hasil

### Evaluasi Original (Biased)
```
Accuracy: 95.5% ‚ùå (Menyesatkan)
Prediksi:
- Bukan Ujaran Kebencian: 955/1000 (95.5%)
- Ujaran Kebencian - Ringan: 0/1000 (0%)
- Ujaran Kebencian - Sedang: 0/1000 (0%)
- Ujaran Kebencian - Berat: 0/1000 (0%)
```

### Evaluasi Balanced (Actual)
```
Accuracy: 73.8% ‚úÖ (Akurat)
Per-class Performance:
- Bukan Ujaran Kebencian: Precision 0.577, Recall 0.930
- Ujaran Kebencian - Ringan: Precision 0.750, Recall 0.450
- Ujaran Kebencian - Sedang: Precision 0.750, Recall 0.600
- Ujaran Kebencian - Berat: Precision 0.882, Recall 0.825
```

## üéØ Rekomendasi Implementasi

### Fase 1: Immediate Fixes (Prioritas Tinggi)

1. **Gunakan Balanced Evaluation**
   ```bash
   python analyze_dataset_distribution.py
   python balanced_evaluation.py
   ```

2. **Update README dengan Hasil Aktual**
   - Ganti metrics yang menyesatkan
   - Tambahkan disclaimer tentang class imbalance
   - Dokumentasikan limitasi model

### Fase 2: Model Improvement (Prioritas Sedang)

1. **Retrain dengan Improved Strategy**
   ```bash
   python improved_training_strategy.py
   ```

2. **Threshold Tuning**
   ```bash
   python threshold_tuning.py
   ```

3. **Evaluasi Model Baru**
   - Bandingkan dengan model original
   - Validasi pada test set terpisah

### Fase 3: Production Deployment (Prioritas Rendah)

1. **Setup Production Environment**
   ```bash
   python production_deployment.py
   ```

2. **Monitoring dan Maintenance**
   - Setup logging dan monitoring
   - Automated model evaluation
   - Data drift detection

## üîç Analisis Mendalam

### Mengapa Model Bias?

1. **Data Ordering**: Dataset tidak di-shuffle, menyebabkan model hanya belajar dari kelas mayoritas
2. **Class Imbalance**: 85% data adalah "Bukan Ujaran Kebencian"
3. **Training Strategy**: Tidak ada handling untuk imbalanced data
4. **Evaluation Bias**: Evaluasi pada data yang ordered memberikan hasil menyesatkan

### Root Cause Analysis

```
Problem: Model predicts everything as "Bukan Ujaran Kebencian"
    ‚Üì
Cause 1: Severe class imbalance (85% vs 15%)
    ‚Üì
Cause 2: No class weighting or sampling strategy
    ‚Üì
Cause 3: Ordered dataset in evaluation
    ‚Üì
Solution: Stratified sampling + Class weighting + Focal loss + Threshold tuning
```

## üìà Expected Improvements

Dengan implementasi semua perbaikan:

### Model Performance
- **Akurasi**: 73.8% ‚Üí 80-85% (target)
- **F1 Macro**: Significant improvement untuk hate speech detection
- **Balanced Performance**: Lebih seimbang antar semua kelas

### Production Readiness
- **Threshold Tuning**: Optimized untuk production use case
- **Monitoring**: Real-time performance tracking
- **Scalability**: Batch processing dan API ready

## ‚ö†Ô∏è Limitasi dan Catatan

### Current Limitations
1. **Dataset Size**: Mungkin perlu lebih banyak data untuk kelas minoritas
2. **Language Complexity**: Bahasa Jawa memiliki variasi dialek
3. **Context Sensitivity**: Hate speech sangat bergantung konteks

### Future Improvements
1. **Data Augmentation**: Synthetic data generation untuk kelas minoritas
2. **Ensemble Methods**: Kombinasi multiple models
3. **Active Learning**: Iterative improvement dengan human feedback
4. **Multi-modal**: Integrasi dengan context information

## üöÄ Quick Start

Untuk implementasi cepat:

```bash
# 1. Analisis dataset
python analyze_dataset_distribution.py

# 2. Evaluasi balanced
python balanced_evaluation.py

# 3. Training improved model (opsional)
python improved_training_strategy.py

# 4. Threshold tuning
python threshold_tuning.py

# 5. Production deployment
python production_deployment.py
```

## üìù Kesimpulan

Model original memiliki **severe bias** yang menyebabkan:
- Akurasi yang menyesatkan (95.5% vs 73.8% aktual)
- Ketidakmampuan mendeteksi hate speech
- Tidak siap untuk production

Dengan implementasi perbaikan yang komprehensif, model dapat:
- Memberikan evaluasi yang akurat
- Mendeteksi hate speech dengan lebih baik
- Siap untuk deployment production

**Rekomendasi**: Implementasikan semua perbaikan sebelum deployment production untuk memastikan model yang reliable dan akurat.