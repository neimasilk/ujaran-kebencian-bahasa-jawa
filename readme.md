# Sistem Deteksi Ujaran Kebencian Bahasa Jawa Menggunakan BERT

Proyek ini bertujuan untuk membangun sebuah sistem yang mampu secara cerdas dan akurat mendeteksi ujaran kebencian dalam teks berbahasa Jawa, dengan memanfaatkan model IndoBERT yang di-fine-tuning.

## Dataset

Dataset yang digunakan dalam proyek ini adalah kumpulan teks Bahasa Jawa yang telah diberi label. Dataset disimpan dalam format CSV dan terletak di `src/data_collection/raw-dataset.csv`. Proses pemuatan dan inspeksi data ditangani oleh script di `src/data_collection/load_csv_dataset.py`.

## Ringkasan Proyek

Proyek ini bertujuan untuk mengembangkan sistem deteksi ujaran kebencian dalam Bahasa Jawa dengan mengintegrasikan Kecerdasan Buatan (AI) dan kearifan lokal. [cite: 20] Model utama yang akan digunakan adalah BERT (Bidirectional Encoder Representations from Transformers)[cite: 19, 22], yang akan dilatih dan disesuaikan untuk mengenali nuansa linguistik dan budaya Bahasa Jawa. [cite: 23, 49]

Meningkatnya penyebaran ujaran kebencian di platform daring, terutama dalam bahasa daerah yang sumber dayanya terbatas, menjadi urgensi utama penelitian ini. [cite: 18, 38] Bahasa Jawa, dengan kompleksitas seperti tingkatan bahasa (ngoko, krama) dan variasi dialek, menyajikan tantangan unik untuk deteksi otomatis. [cite: 39, 40]

## Tujuan Utama

1.  Mengembangkan model *machine learning* berbasis BERT yang akurat untuk mendeteksi ujaran kebencian dalam Bahasa Jawa. [cite: 19, 21]
2.  Mengintegrasikan aspek kearifan lokal dalam proses pelabelan data dan analisis model untuk meningkatkan pemahaman konteks budaya. [cite: 20, 23]
3.  Menghasilkan *dataset* ujaran kebencian Bahasa Jawa berlabel (ringan, sedang, berat) yang dapat digunakan untuk penelitian selanjutnya. [cite: 7, 57, 96, 121]
4.  Membangun prototipe API berbasis web untuk demonstrasi dan pengujian sistem deteksi. [cite: 7, 62, 108]

## Teknologi yang Digunakan (Direncanakan)

* **Model AI:** BERT (IndoBERT sebagai basis) [cite: 58, 100]
* **Bahasa Pemrograman:** Python
* **Framework/Library:**
    * Hugging Face Transformers (untuk BERT)
    * Scikit-learn (untuk evaluasi)
    * Pandas, NumPy (untuk manipulasi data)
    * NLTK, Sastrawi (atau library NLP Indonesia/Jawa lainnya untuk preprocessing)
    * Flask/FastAPI (untuk API prototipe) [cite: 108]
* **Version Control:** Git, GitHub

## Struktur Proyek

```
.
â”œâ”€â”€ data/               # Data mentah dan yang sudah diproses
â”‚   â”œâ”€â”€ raw/           # Data mentah
â”‚   â””â”€â”€ processed/     # Data yang sudah diproses
â”œâ”€â”€ notebooks/         # Jupyter notebooks untuk eksperimen
â”œâ”€â”€ src/              # Source code
â”‚   â”œâ”€â”€ data_collection/  # Script pengumpulan data
â”‚   â”œâ”€â”€ preprocessing/    # Script preprocessing
â”‚   â”œâ”€â”€ modelling/       # Script model ML
â”‚   â”œâ”€â”€ api/             # API endpoints
â”‚   â””â”€â”€ utils/           # Fungsi utilitas
â”œâ”€â”€ models/           # Model yang sudah dilatih
â”œâ”€â”€ tests/           # Unit tests
â””â”€â”€ docs/            # Dokumentasi tambahan
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Git
- Virtual environment (recommended)
- DeepSeek API Key (untuk pelabelan data)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd ujaran-kebencian-bahasa-jawa

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-deepseek.txt

# Setup DeepSeek API (untuk pelabelan data)
python setup_deepseek_env.py

# Verify installation
python src/data_collection/verify_dataset.py
```

## Setup Environment

Proyek ini menggunakan Anaconda untuk manajemen environment dan package Python. Berikut langkah-langkah untuk setup environment:

1. Install [Anaconda](https://www.anaconda.com/download)
2. Buat environment conda baru:
   ```bash
   conda create -n ujaran python=3.11
   ```
3. Aktifkan environment:
   ```bash
   conda activate ujaran
   ```
4. Install semua dependencies dari requirements.txt:
   ```bash
   pip install -r requirements.txt
   ```

Detail lebih lanjut tentang setup environment dapat dilihat di `memory-bank/environment-setup.md`.

## ğŸ“Š Current Progress

### âœ… Completed
- [x] Project structure setup
- [x] Data collection pipeline
- [x] Basic preprocessing functions
- [x] Unit testing infrastructure
- [x] API documentation
- [x] **DeepSeek V3 API integration untuk pelabelan**

### ğŸ”„ In Progress
- [x] **Data labeling dengan DeepSeek V3 API**
- [ ] Quality assurance hasil pelabelan
- [ ] Model development dengan dataset berlabel
- [ ] API implementation

### â³ Planned
- [ ] Training pipeline dengan dataset DeepSeek
- [ ] Web interface
- [ ] Deployment setup
- [ ] Performance optimization

## ğŸ› ï¸ Development Workflow

Proyek ini menggunakan **Vibe Coding V1.4** dengan kolaborasi AI-Human:

### Team Structure
- **Human**: Mukhlis Amien (Architect), Hashfi (Developer)
- **AI**: jules_dokumen (Documentation), jules_dev1 & jules_dev2 (Development)

### Baby-steps Approach
1. Setiap iterasi dibagi menjadi baby-steps kecil
2. Setiap baby-step memiliki deliverable yang jelas
3. Testing dan dokumentasi terintegrasi
4. AI commit hasil kerja mereka sendiri

### Current Baby-step
**Data Labeling dengan DeepSeek V3 API** ğŸ”„ DALAM PROGRESS
- âœ… Setup DeepSeek API integration
- âœ… Dokumentasi lengkap penggunaan DeepSeek
- â³ Processing dataset dengan AI labeling
- â³ Quality assurance dan validasi manual

## ğŸ“ Project Structure

```
ujaran-kebencian-bahasa-jawa/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_collection/     # Data loading, preprocessing, DeepSeek labeling
â”‚   â”œâ”€â”€ model/              # Model development
â”‚   â””â”€â”€ api/                # API implementation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw dataset
â”‚   â””â”€â”€ processed/          # Processed dataset, DeepSeek results
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ docs/                   # Documentation, DeepSeek guide
â”œâ”€â”€ vibe-guide/            # Development guidelines
â”œâ”€â”€ memory-bank/           # Project memory dan progress
â”œâ”€â”€ baby-steps-archive/    # Archive completed steps
â”œâ”€â”€ setup_deepseek_env.py  # DeepSeek API setup
â”œâ”€â”€ requirements-deepseek.txt # DeepSeek dependencies
â””â”€â”€ .env                   # API keys (tidak di-commit)
```

## ğŸ”§ Key Features

### Data Pipeline
- Robust CSV loading dengan error handling
- **DeepSeek V3 API integration untuk auto-labeling**
- Data validation dan cleaning
- Preprocessing untuk Bahasa Jawa

### AI-Powered Labeling
- **Automated labeling dengan DeepSeek V3**
- Pemahaman konteks budaya Bahasa Jawa
- Confidence scoring dan reasoning
- Quality assurance workflow

### Testing Infrastructure
- Unit tests dengan pytest
- Coverage reporting
- Automated testing pipeline

### Documentation
- API reference lengkap
- **DeepSeek integration guide**
- Development guidelines
- Progress tracking

## Panduan Kontribusi

Untuk berkontribusi pada proyek ini, silakan baca:
1. Petunjuk pekerjaan manual di [`memory-bank/petunjuk pekerjaan manual.md`](memory-bank/petunjuk-pekerjaan-manual.md)
2. Setup environment di [`memory-bank/environment-setup.md`](memory-bank/environment-setup.md)

(Akan dilengkapi dengan panduan kontribusi lainnya jika proyek bersifat kolaboratif)

## Lisensi

(Akan ditentukan kemudian)

---